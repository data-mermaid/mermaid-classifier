#
# Settings - ML inputs
#

# If you're reading either site's training data from a bucket other than the
# default of coral-reef-training, specify the bucket name here.
CORALNET_TRAIN_DATA_BUCKET=my-bucket
MERMAID_TRAIN_DATA_BUCKET=my-bucket-2

# If you're putting annotations files in different locations from what is
# expected by default, specify here. Certain curly-braced placeholders are
# available to use.
CORALNET_ANNOTATIONS_CSV_PATTERN=s3://{coralnet_train_data_bucket}/s{source_id}/annotations.csv
MERMAID_ANNOTATIONS_PARQUET_PATTERN=s3://{mermaid_train_data_bucket}/mermaid/mermaid_confirmed_annotations.parquet

# Location of the feature-extractor weights, as a local path or S3 URI.
# Required by the annotation viewer when classifying the input image.
WEIGHTS_LOCATION=s3://my-bucket/weights.pt

# Region to access AWS resources in.
AWS_REGION=us-east-1

# The easiest way to access AWS resources is to be on an AWS instance which
# connects to the instance metadata service (IMDS) for credentials.
# However, these variables offer other options, such as:
# - Set AWS_ANONYMOUS to True; this explicitly tells AWS that you're not trying
#   to authenticate, which allows access to public S3 files without setting up
#   anything else.
# - Sign into AWS through SSO, and get a temporary key, secret, and token for
#   the role of your choice. Set those values here.
# These variables are used for accessing AWS (mainly S3) through pyspacer,
# DuckDB, and s3fs.
# Note that the session token may need to be within quotes, since the token
# will typically contain equals signs.
AWS_ANONYMOUS=False
AWS_KEY_ID=...
AWS_SECRET=...
AWS_SESSION_TOKEN="..."


#
# Settings - Other
#

# URI of the MLflow tracking server.
#
# The URI format depends on how the server's set up. For example, this
# could be an ARN referring to a SageMaker MLflow tracking server, starting
# with 'arn:aws:sagemaker:', as demonstrated below.
# Or it could be a localhost address, like http://127.0.0.1:8080
#
# You'll basically need to set this unless you train with
# disable_mlflow = True.
MLFLOW_TRACKING_SERVER=arn:aws:sagemaker:us-east-1:123456781234:mlflow-tracking-server/my-classifiers

# Filesystem directory to use for caching extractor weights that
# were downloaded from S3 or from a URL.
# This is required if loading weights from such a source.
SPACER_EXTRACTORS_CACHE_DIR=/home/sagemaker-user/extractors_cache

# When reading in training data, if the percent of feature vectors missing
# from storage is above this number, training aborts.
TRAINING_INPUTS_PERCENT_MISSING_ALLOWED=0

# This pyspacer training setting is:
# - A cap on the reference set size, as a number of point-features
# - The size of batches used during training
# Raising this can better accommodate rare classes in large training
# runs, and can improve the trainer's ability to calibrate between
# epochs.
# However, this setting is also tied to training's memory usage,
# so monitor memory usage when increasing this setting. If the system
# becomes unresponsive during pyspacer training, definitely try
# lowering this.
#
# mermaid-classifier's default is calculated based on the total amount
# of system RAM, and based on assumptions that may or may not apply to
# your system and training setup.
SPACER_REF_SET_MAX_SIZE=50000

# When retrieving or saving models, this is the number of
# exponential-backoff retries that MLflow will attempt when it's
# having trouble connecting.
# Default 7, but that takes forever; 2 is recommended.
MLFLOW_HTTP_REQUEST_MAX_RETRIES=7

# Default experiment name when logging an experiment run to MLflow.
# This is basically used to categorize experiment runs and their associated
# models.
# If a training run doesn't specify such a name, AND this name is left
# blank, then MLflow's default of "Default" is used.
MLFLOW_DEFAULT_EXPERIMENT_NAME=My experiment
